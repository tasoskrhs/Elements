{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notebook version of GenerativeExampleEngage.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "# sys.path.append(\"../../../\")\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn.norm import GraphNorm\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "from CreateScenes import objs, CreateSceneFromGNNOutput\n",
    "from Elements.pyGLV.GL.Scene import Scene\n",
    "import Converter as Converter\n",
    "import random\n",
    "import numpy as np\n",
    "import features.usd.UsdImporterENGAGE as SceneLoader\n",
    "from Elements.pyECSS.Entity import Entity\n",
    "from Elements.pyECSS.Component import BasicTransform, RenderMesh, Camera\n",
    "from CreateScenes import CreateRoomScene,CreateORScene,CreatePaperScene\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if not os.path.exists(\"Training_Scenes\"):\n",
    "#     import requests\n",
    "#     import zipfile\n",
    "\n",
    "#     # Dropbox link to the zip file\n",
    "#     dropbox_link = \"https://www.dropbox.com/s/nv9lm9jyjwx7tj6/Training_Scenes2.zip?dl=1\"\n",
    "\n",
    "#     # Download the zip file\n",
    "#     response = requests.get(dropbox_link, stream=True)\n",
    "#     zip_filename = \"file.zip\"\n",
    "\n",
    "#     with open(zip_filename, \"wb\") as file:\n",
    "#         for chunk in response.iter_content(chunk_size=128):\n",
    "#             file.write(chunk)\n",
    "\n",
    "#     # Extract the contents of the zip file\n",
    "#     with zipfile.ZipFile(zip_filename, \"r\") as zip_ref:\n",
    "#         zip_ref.extractall(\"Training_Scenes\")\n",
    "\n",
    "#     # Clean up the downloaded zip file\n",
    "#     import os\n",
    "\n",
    "#     os.remove(zip_filename)\n",
    "# else:\n",
    "#     print(\"Skipping download, scenes already exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numscenes = 1000\n",
    "mydata = []\n",
    "myy = []\n",
    "tempobs = objs.copy()\n",
    "tempobs.remove(\"root\")\n",
    "label_emb = 8\n",
    "features = 7\n",
    "latent_dim = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VariationalGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(VariationalGCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels)  # cached only for transductive learning\n",
    "        self.conv2 = GCNConv(2 * out_channels, 4 * out_channels)\n",
    "        self.conv_mu = GCNConv(2 * out_channels, out_channels)\n",
    "        self.conv_logstd = GCNConv(2 * out_channels, out_channels)\n",
    "        self.norm = GraphNorm(in_channels)\n",
    "        self.lRelu = torch.nn.LeakyReLU(0.1)\n",
    "\n",
    "    def forward(self, x, edge_index, batch=None):\n",
    "        if self.training:\n",
    "            x = self.norm(x, batch)\n",
    "        else:\n",
    "            x = self.norm(x)\n",
    "        x = self.lRelu(self.conv1(x, edge_index))\n",
    "        # x = self.lRelu(self.conv2(x, edge_index))\n",
    "        mu, logstd = self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)\n",
    "        return self.reparametrize(mu, logstd), mu, logstd\n",
    "\n",
    "    def reparametrize(self, mu, logstd):\n",
    "        if self.training:\n",
    "            return mu + torch.randn_like(logstd) * torch.exp(logstd)\n",
    "        else:\n",
    "            return mu\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VariationalGCNDecoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(VariationalGCNDecoder, self).__init__()\n",
    "        self.lin1 = torch.nn.Linear(in_channels, out_channels)\n",
    "        self.lin3 = torch.nn.Linear(out_channels, out_channels)\n",
    "        self.lin2 = torch.nn.Linear(in_channels, in_channels)\n",
    "        self.lRelu = torch.nn.LeakyReLU(0.1)\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.lRelu(self.lin1(z))\n",
    "        x = self.lin3(x)\n",
    "        # value = (z[edge_index[0]] * z[edge_index[1]]).sum(dim=1)\n",
    "        return x, z\n",
    "\n",
    "    def forward_for_loss(self, z, edge_index):\n",
    "        zhat = self.lin2(z)\n",
    "        value = (z[edge_index[0]] * zhat[edge_index[1]]).sum(dim=1)\n",
    "        return torch.sigmoid(value)\n",
    "\n",
    "    def forward_all(self, z):\n",
    "        r\"\"\"Decodes the latent variables :obj:`z` into a probabilistic dense\n",
    "        adjacency matrix.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): The latent space :math:`\\mathbf{Z}`.\n",
    "            sigmoid (bool, optional): If set to :obj:`False`, does not apply\n",
    "                the logistic sigmoid function to the output.\n",
    "                (default: :obj:`True`)\n",
    "        \"\"\"\n",
    "        zhat = self.lin2(z)\n",
    "        adj = torch.matmul(z, zhat.t())\n",
    "        return torch.sigmoid(adj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VariationalAE(torch.nn.Module):\n",
    "    def __init__(self, encoder, decoder, label_emb):\n",
    "        super(VariationalAE, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.__mu__, self.__logstd__ = None, None\n",
    "        # self.__logstd__ = self.__logstd__.clamp(max=MAX_LOGSTD)\n",
    "        self.labelEmb = torch.nn.Embedding(5, label_emb) # <-- NOTE: changed first argumnert in emebedding layer!\n",
    "\n",
    "    def forward(self, x, edge_index, y, batch=None):\n",
    "        y = self.labelEmb(y) # dim: (bs x 1) x labeL_emb\n",
    "        # y = y.repeat(x.) # mine: replicate y along each node (x 1st dim is bs X trs_nodes )\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "        MAX_LOGSTD = 10\n",
    "        z, mu, logstd = self.encoder(x, edge_index, batch)\n",
    "        self.__mu__ = mu\n",
    "        self.__logstd__ = logstd\n",
    "        self.__logstd__ = self.__logstd__.clamp(max=MAX_LOGSTD)\n",
    "        z = torch.cat((z, y), dim=1)\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def recon_loss(self, z, pos_edge_index,\n",
    "                   neg_edge_index=None):\n",
    "        r\"\"\"Given latent variables :obj:`z`, computes the binary cross\n",
    "        entropy loss for positive edges :obj:`pos_edge_index` and negative\n",
    "        sampled edges.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): The latent space :math:`\\mathbf{Z}`.\n",
    "            pos_edge_index (torch.Tensor): The positive edges to train against.\n",
    "            neg_edge_index (torch.Tensor, optional): The negative edges to\n",
    "                train against. If not given, uses negative sampling to\n",
    "                calculate negative edges. (default: :obj:`None`)\n",
    "        \"\"\"\n",
    "        EPS = 1e-15\n",
    "        out = self.decoder.forward_for_loss(z, pos_edge_index)\n",
    "        pos_loss = -torch.log(out + EPS).mean()\n",
    "\n",
    "        if neg_edge_index is None:\n",
    "            neg_edge_index = negative_sampling(pos_edge_index, z.size(0))\n",
    "        out = self.decoder.forward_for_loss(z, neg_edge_index)\n",
    "        neg_loss = -torch.log(1 - out + EPS).mean()\n",
    "\n",
    "        return pos_loss + neg_loss\n",
    "\n",
    "    def kl_loss(self, mu=None,\n",
    "                logstd=None):\n",
    "        r\"\"\"Computes the KL loss, either for the passed arguments :obj:`mu`\n",
    "        and :obj:`logstd`, or based on latent variables from last encoding.\n",
    "\n",
    "        Args:\n",
    "            mu (torch.Tensor, optional): The latent space for :math:`\\mu`. If\n",
    "                set to :obj:`None`, uses the last computation of :math:`\\mu`.\n",
    "                (default: :obj:`None`)\n",
    "            logstd (torch.Tensor, optional): The latent space for\n",
    "                :math:`\\log\\sigma`.  If set to :obj:`None`, uses the last\n",
    "                computation of :math:`\\log\\sigma^2`. (default: :obj:`None`)\n",
    "        \"\"\"\n",
    "        MAX_LOGSTD = 10\n",
    "        mu = self.__mu__ if mu is None else mu\n",
    "        logstd = self.__logstd__ if logstd is None else logstd.clamp(\n",
    "            max=MAX_LOGSTD)\n",
    "        return -0.5 * torch.mean(\n",
    "            torch.sum(1 + 2 * logstd - mu ** 2 - logstd.exp() ** 2, dim=1))\n",
    "\n",
    "    def add_to_scene(self, additions, data=None, test=False):\n",
    "        scene = None\n",
    "        if data is not None and test == False:\n",
    "            x = data.x\n",
    "            y = data.y\n",
    "            edge = data.edge_index\n",
    "            yInitEmb = self.labelEmb(y)\n",
    "            xInitEmb = torch.cat((x, yInitEmb), dim=1)\n",
    "            z, _, _ = self.encoder(xInitEmb, edge)\n",
    "            z = torch.cat((z, yInitEmb), dim=1)\n",
    "            additionZ = torch.randn(len(additions), latent_dim).to(device)\n",
    "            additionsTensor = torch.LongTensor(additions).to(device)\n",
    "            yAdditionEmb = self.labelEmb(additionsTensor)\n",
    "            additionZ = torch.cat((additionZ, yAdditionEmb), dim=1)\n",
    "            newY = torch.cat((y, additionsTensor), dim=0)\n",
    "            newgraphZ = torch.cat((z, additionZ), dim=0)\n",
    "            recon = self.decoder(newgraphZ)\n",
    "            recon = recon[0]\n",
    "            adj = self.decoder.forward_all(newgraphZ)\n",
    "            Scene.reset_instance()\n",
    "            scene = CreateSceneFromGNNOutput(recon, adj, newY, True)\n",
    "        elif data is not None and test:\n",
    "            x = data.x\n",
    "            y = data.y\n",
    "            allz = None\n",
    "            for i in range(x.shape[0]):\n",
    "                tempx = x[i].reshape(1, x.shape[1])\n",
    "                tempy = y[i].reshape(1, )\n",
    "                edge = torch.zeros((2, 1)).long().to(device)\n",
    "                yInitEmb = self.labelEmb(tempy)\n",
    "                xInitEmb = torch.cat((tempx, yInitEmb), dim=1)\n",
    "                z, _, _ = self.encoder(xInitEmb, edge)\n",
    "                z = torch.cat((z, yInitEmb), dim=1)\n",
    "                if allz is None:\n",
    "                    allz = z\n",
    "                else:\n",
    "                    allz = torch.cat((allz, z), dim=0)\n",
    "            additionZ = torch.randn(len(additions), latent_dim).to(device)\n",
    "            additionsTensor = torch.LongTensor(additions).to(device)\n",
    "            yAdditionEmb = self.labelEmb(additionsTensor)\n",
    "            additionZ = torch.cat((additionZ, yAdditionEmb), dim=1)\n",
    "            newY = torch.cat((y, additionsTensor), dim=0)\n",
    "            newgraphZ = torch.cat((allz, additionZ), dim=0)\n",
    "            recon = self.decoder(newgraphZ)\n",
    "            recon = recon[0]\n",
    "            adj = self.decoder.forward_all(newgraphZ)\n",
    "            Scene.reset_instance()\n",
    "            scene = CreateSceneFromGNNOutput(recon, adj, newY, True)\n",
    "        else:\n",
    "            additions.append(0)\n",
    "            additionZ = torch.randn(len(additions), latent_dim).to(device)\n",
    "            additionsTensor = torch.LongTensor(additions).to(device)\n",
    "            yAdditionEmb = self.labelEmb(additionsTensor)\n",
    "            additionZ = torch.cat((additionZ, yAdditionEmb), dim=1)\n",
    "            newY = additionsTensor\n",
    "            newgraphZ = additionZ\n",
    "            recon = self.decoder(newgraphZ)\n",
    "            recon = recon[0]\n",
    "            adj = self.decoder.forward_all(newgraphZ)\n",
    "            Scene.reset_instance()\n",
    "            scene = CreateSceneFromGNNOutput(recon, adj, newY, True)\n",
    "        return scene\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from os import path\n",
    "# mystr = path.join('../../Training_Scenes/Training_Scenes2/scene' + str(1) + '.usd')\n",
    "# mystr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls -lah ../../../Training_Scenes/Training_Scenes2/scene1.usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD 1 scene\n",
    "Scene.reset_instance()\n",
    "scene = Scene()\n",
    "rootEntity = scene.world.createEntity(Entity(name=\"RooT\"))\n",
    "# SceneLoader.LoadScene(scene, \"../../../Training_Scenes/Training_Scenes2/scene\" + str(1) + \".usd\")\n",
    "SceneLoader.LoadScene(scene, \"./Training_Scenes/Training_Scenes2/scene\" + str(1) + \".usd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "# from CreateScenes import view_scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view_scene(scene)    <---- FAILS HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert 1 scene --> graph\n",
    "# data = Converter.ECStoGNNSimpleTransQuat(scene)\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert back to ECS\n",
    "# data_ECS = Converter.GNNtoECS(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create a default room scene and move the chair (ONCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scene.reset_instance()\n",
    "scene = CreateRoomScene(visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comp in scene.world.components:\n",
    "\n",
    "    if isinstance(comp, BasicTransform):\n",
    "        if comp.parent.name == 'Chair':  # 'Chair1' # 'Lamp'\n",
    "            # translate this!\n",
    "            comp.translation[1] = 0.5 # 1 => Z-axis\n",
    "            # NOTE: modify BasicTransform as well!!\n",
    "            comp.trs[1][-1] = 0.5  # trs is 4x4 with the last COL the translation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just verify that is changed\n",
    "# scene.world.components\n",
    "\n",
    "# visualize\n",
    "from CreateScenes import view_scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_scene(scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 5\n",
    "# for i in range(N):\n",
    "#     dz = 1./float(N)\n",
    "#     new_z = float(i) * dz\n",
    "#     print(new_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create multiple scenes and move the chair infinitesimally in Z-axis (so that it doesn't collide with other objects...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGNN_chairs = []\n",
    "N = 5\n",
    "for idx in range(N): #(20):\n",
    "    Scene.reset_instance()\n",
    "    scene = CreateRoomScene(visualize=False)\n",
    "\n",
    "    # Z-axis translation\n",
    "    dz = 1./float(N)\n",
    "    new_z = float(idx) * dz\n",
    "\n",
    "    for i, comp in enumerate(scene.world.components):\n",
    "\n",
    "        if isinstance(comp, BasicTransform):\n",
    "            if comp.parent.name == 'Chair':  # 'Chair1' # 'Lamp'\n",
    "                # translate this!\n",
    "                scene.world.components[i].translation[1] = new_z # 1 => Z-axis\n",
    "                # NOTE: modify BasicTransform as well!!\n",
    "                scene.world.components[i].trs[1][-1] =  new_z # trs is 4x4 with the last COL the translation \n",
    "                \n",
    "    # CONVERT to graph\n",
    "    SceneGNN = Converter.ECStoGNNNoNoise(scene) # NOTE that no noise is used, the only diff is the displaced CHAIR!\n",
    "    # conditional variable must be a tensor\n",
    "    y = []\n",
    "    n_trs_nodes = SceneGNN['trs'].x.shape[0] # number of BasisTrs nodes\n",
    "    y = [idx] * n_trs_nodes # y.append(idx)\n",
    "    SceneGNN.t = torch.LongTensor(np.asarray(y)) # time conditional variable. ==> has to be integer\n",
    "\n",
    "    dataGNN_chairs.append(SceneGNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = []\n",
    "dummy = [idx] * SceneGNN['trs'].x.shape[0]\n",
    "dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataGNN_chairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize LAST scene. I cannot save a list of scenes with discrete translations using a variable to modify them.\n",
    "# view_scene(scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Verify that: default Chair trans is: (-0.2, 0, 0)\n",
    "# Scene.reset_instance()\n",
    "# def_scene = CreateRoomScene(visualize=False)\n",
    "\n",
    "# for comp in def_scene.world.components:\n",
    "\n",
    "#         if isinstance(comp, BasicTransform):\n",
    "#             if comp.parent.name == 'Chair':  # 'Chair1' # 'Lamp'\n",
    "#                 # translate this!\n",
    "#                 print(comp.translation)\n",
    "#                 print(comp.trs) \n",
    "\n",
    "# print('======Modify====')\n",
    "# # modify and re-print\n",
    "# for i, comp in enumerate(def_scene.world.components):\n",
    "\n",
    "#         if isinstance(comp, BasicTransform):\n",
    "#             if comp.parent.name == 'Chair':  # 'Chair1' # 'Lamp'\n",
    "#                 # translate this!\n",
    "#                 def_scene.world.components[i].translation[1] = 0.71\n",
    "#                 def_scene.world.components[i].trs[1][-1] = 0.71\n",
    "\n",
    "# print('======print ====')\n",
    "\n",
    "# for comp in def_scene.world.components:\n",
    "\n",
    "#         if isinstance(comp, BasicTransform):\n",
    "#             if comp.parent.name == 'Chair':  # 'Chair1' # 'Lamp'\n",
    "#                 # translate this!\n",
    "#                 print(comp.translation)\n",
    "#                 print(comp.trs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[ 0.1,  0.,   0., -0.2],\n",
    " [ 0.,   0.1,  0.,   0. ],\n",
    " [ 0.,   0.,   0.1,  0. ],\n",
    " [ 0.,   0.,   0.,   1. ]])\n",
    "print('Default chair trs matrix is=', A)\n",
    "print('-------')\n",
    "print('flattened:', A.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGNN_chairs[0]['trs'].x  # first scene trs matrices. The THIRD corresponds to the chair (default chair). CHECK THAT 8-th position == 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGNN_chairs[1]['trs'].x  # SECOND scene trs matrices. The THIRD corresponds to the chair (MOVED chair in z-axis by 0.2) CHECK THAT 8-th position == 0.2!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGNN_chairs[2]['trs'].x  # THIRD scene trs matrices. The THIRD corresponds to the chair (MOVED chair in z-axis by 0.4) CHECK THAT 8-th position == 0.4!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGNN_chairs[2].t # time conditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGNN_chairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGNN_chairs[0]['entity', 'trsparent', 'trs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGNN_chairs[0].t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## attempt to run the cond GVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-define parameters\n",
    "features = 16 # all the trs matrix (flattened)\n",
    "range_of_embs = 5 # possible discrete items in the embedding space. First argument of torch.nn.Embedding(num_embeddings= , embedding_dim= ) \n",
    "label_emb = 3 # let's just use a low one. Second argument of torch.nn.Embedding(num_embeddings= , embedding_dim= )  \n",
    "latent_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eachrun = np.zeros((100,2)) #((100, 10))  # epochs x re-runs\n",
    "# for run in range(2):  # (10):  # re-runs of the same dataset...\n",
    "#     print(\"Run:\", run)\n",
    "\n",
    "\n",
    "# random.shuffle(mydata)\n",
    "mydata = dataGNN_chairs[:5]  # mydata[:100] # [:500]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "encoder = VariationalGCNEncoder(features + label_emb, latent_dim)\n",
    "decoder = VariationalGCNDecoder(latent_dim + label_emb, features)\n",
    "model = VariationalAE(encoder, decoder, label_emb).to(device)  # TODO: I should use the additional agrument: range_of_embs\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 100\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(mydata, batch_size=batch_size, shuffle=True)\n",
    "criterion = torch.nn.MSELoss()\n",
    "model.train()\n",
    "allrows = []\n",
    "alllosses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    losses = []\n",
    "    for t in train_loader:\n",
    "        t = t.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        x, z = model(t['trs'].x, t['entity', 'trsparent', 'trs'].edge_index, t.t, t['trs'].batch) # model(t.x, t.edge_index, t.y, t.batch)\n",
    "        loss1 = model.recon_loss(z, t.edge_index)  # reconstruction loss on edges\n",
    "        loss2 = criterion(x, t.x)                  # reconstruction loss on node embeds\n",
    "        loss3 = (1 / t.num_nodes) * model.kl_loss()  # Regularization loss on latent space (why does it have a mean in kl_loss() definition?)\n",
    "        loss = loss1 + loss2 + loss3            # <-- TODO: add weights as in beta-VAE\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch \", i, \": Loss:\", np.mean(np.asarray(losses)))\n",
    "    # eachrun[i][run] = np.mean(np.asarray(losses))\n",
    "    # row = [\"Epoch \" + str(i), str(np.mean(np.asarray(losses)))]\n",
    "    # allrows.append(row)\n",
    "    # alllosses.append(np.mean(np.asarray(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata[0].t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load usd data to Scenes (paper Section 5.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = []\n",
    "for i in range(2): # (1000):\n",
    "    Scene.reset_instance()\n",
    "    scene = Scene()\n",
    "    rootEntity = scene.world.createEntity(Entity(name=\"RooT\"))\n",
    "    SceneLoader.LoadScene(scene, \"./Training_Scenes/Training_Scenes2/scene\" + str(i) + \".usd\")\n",
    "    # This line can be changed to different GA converting functions, for example TRS, CGA etc.\n",
    "    data = Converter.ECStoGNNSimpleTransQuat(scene)\n",
    "    print('i', i)\n",
    "    mydata.append(data)  # MINE <----------!!!!!!!!!!!!11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mydata[0].x)\n",
    "print('----')\n",
    "print(mydata[0].y)\n",
    "print('----')\n",
    "print(mydata[0].edge_index)\n",
    "\n",
    "print('====== 2nd ======')\n",
    "\n",
    "print(mydata[1].x)\n",
    "print('----')\n",
    "print(mydata[1].y)\n",
    "print('----')\n",
    "print(mydata[1].edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear memory\n",
    "# mydata =[]  # does not free RAM\n",
    "# mydata.clear() # does NOT free RAM, only contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mydata[0])\n",
    "print(\"=======\")\n",
    "print('labels= ', mydata[0].y) # NOTE: this varies from scene to scene!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print parameters set at the beggining\n",
    "print('label_emb =', label_emb) #  why??\n",
    "print('features =', features) # 2nd dim of data.x\n",
    "print('latent_dim =', latent_dim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc \n",
    "\n",
    "# print(gc.get_threshold())\n",
    "\n",
    "# del(mydata) # should work if there are NO references to 'mydata'... Didn't work for me... PROBABLY due to last 'data' living in CUDA\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eachrun = np.zeros((100,2)) #((100, 10))  # epochs x re-runs\n",
    "for run in range(2):  # (10):  # re-runs of the same dataset...\n",
    "    print(\"Run:\", run)\n",
    "    random.shuffle(mydata)\n",
    "    mydata = mydata[:100] # [:500]\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    encoder = VariationalGCNEncoder(features + label_emb, latent_dim)\n",
    "    decoder = VariationalGCNDecoder(latent_dim + label_emb, features)\n",
    "    model = VariationalAE(encoder, decoder, label_emb).to(device)   \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    epochs = 100\n",
    "    batch_size = 8\n",
    "    train_loader = DataLoader(mydata, batch_size=batch_size, shuffle=True)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    model.train()\n",
    "    allrows = []\n",
    "    alllosses = []\n",
    "    for i in range(epochs):\n",
    "        losses = []\n",
    "        for t in train_loader:\n",
    "            t = t.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            x, z = model(t.x, t.edge_index, t.y, t.batch)\n",
    "            loss1 = model.recon_loss(z, t.edge_index)\n",
    "            loss2 = criterion(x, t.x)\n",
    "            loss3 = (1 / t.num_nodes) * model.kl_loss()  # new line\n",
    "            loss = loss1 + loss2 + loss3\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"Epoch \", i, \": Loss:\", np.mean(np.asarray(losses)))\n",
    "        eachrun[i][run] = np.mean(np.asarray(losses))\n",
    "        row = [\"Epoch \" + str(i), str(np.mean(np.asarray(losses)))]\n",
    "        allrows.append(row)\n",
    "        alllosses.append(np.mean(np.asarray(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elements",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
